{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a36b9a3",
   "metadata": {},
   "source": [
    "# LSTM English-to-French"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f219bf47",
   "metadata": {},
   "source": [
    "## I. Build the vocab before training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7446293",
   "metadata": {},
   "source": [
    "### Step 1: Prepare the dataset & tokenize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49550908",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "# Tokenizers\n",
    "en_tokenizer = get_tokenizer(\"spacy\", language=\"en_core_web_sm\")\n",
    "fr_tokenizer = get_tokenizer(\"spacy\", language=\"fr_core_news_sm\")\n",
    "\n",
    "SPECIAL_TOKENS = [\"<unk>\", \"<pad>\", \"<bos>\", \"<eos>\"]\n",
    "MAX_VOCAB = 10_004\n",
    "UNK_TOKEN = \"<unk>\"\n",
    "\n",
    "# --- Paths ---\n",
    "train_file_en = \"./Data/train.en\"\n",
    "train_file_fr = \"./Data/train.fr\"\n",
    "\n",
    "# --- Function ---\n",
    "def get_tokens(path, tokenizer):\n",
    "    all_tokens = []\n",
    "    with open(path, encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            all_tokens.append(tokenizer(line.strip()))\n",
    "    return all_tokens\n",
    "\n",
    "# --- Load tokens ---\n",
    "enToken = get_tokens(train_file_en, en_tokenizer)\n",
    "frToken = get_tokens(train_file_fr, fr_tokenizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a07d61",
   "metadata": {},
   "source": [
    "### Step 2: Build the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74a871e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English vocab size: 10004\n",
      "French vocab size: 10004\n",
      "Two:  [19]\n",
      "Young:  [25]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "# ==== Build vocab function ====\n",
    "\n",
    "def yield_tokens(token_list):\n",
    "    for tokens in token_list:\n",
    "        yield tokens\n",
    "\n",
    "# ==== English vocab ====\n",
    "\n",
    "en_vocab = build_vocab_from_iterator(\n",
    "    yield_tokens(enToken),\n",
    "    specials=SPECIAL_TOKENS,\n",
    "    max_tokens=MAX_VOCAB\n",
    ")\n",
    "\n",
    "en_vocab.set_default_index(en_vocab[UNK_TOKEN])\n",
    "\n",
    "# ==== French vocab ====\n",
    "\n",
    "fr_vocab = build_vocab_from_iterator(\n",
    "    yield_tokens(frToken),\n",
    "    specials=SPECIAL_TOKENS,\n",
    "    max_tokens=MAX_VOCAB\n",
    ")\n",
    "\n",
    "fr_vocab.set_default_index(fr_vocab[UNK_TOKEN])\n",
    "\n",
    "# ==== Check vocab size ====\n",
    "print(\"English vocab size:\", len(en_vocab))\n",
    "print(\"French vocab size:\", len(fr_vocab))\n",
    "print(\"Two: \",en_vocab(['Two']))\n",
    "print(\"Young: \",en_vocab(['young']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec78430",
   "metadata": {},
   "source": [
    "Finally, we have built two vocabularies for the two languages. Each vocabulary contains the 10,000 most frequent words in the dataset, along with four special tokens: <`unk`>, <`pad`>, <`sos`>, and <`eos`>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2815fc6",
   "metadata": {},
   "source": [
    "## II. Padding & Tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9273011c",
   "metadata": {},
   "source": [
    "### Step 1: Sync the lenght of batch with pad_sequence and pack padded sequence with collate_fn() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a59225d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\n",
    "\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "def collate_fn(sentences, vocab, pad_token='<pad>'):\n",
    "    pad_idx = vocab[pad_token]\n",
    "    batch_indices = [torch.tensor([vocab[token] for token in sentence]) for sentence in sentences]\n",
    "    \n",
    "    lengths = torch.tensor([len(seq) for seq in batch_indices])\n",
    "    \n",
    "    src_padded = pad_sequence(batch_indices, batch_first=True, padding_value=pad_idx)\n",
    "    return src_padded, lengths\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52494795",
   "metadata": {},
   "source": [
    "### Step 2: Initiliazel Dataloader to control for trainning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8515f9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Batch 0 ===\n",
      "Padded batch shape: torch.Size([128, 22])\n",
      "\n",
      "=== Batch 1 ===\n",
      "Padded batch shape: torch.Size([128, 35])\n",
      "\n",
      "=== Batch 2 ===\n",
      "Padded batch shape: torch.Size([128, 34])\n",
      "\n",
      "=== Batch 3 ===\n",
      "Padded batch shape: torch.Size([128, 26])\n",
      "\n",
      "=== Batch 4 ===\n",
      "Padded batch shape: torch.Size([128, 29])\n",
      "\n",
      "=== Batch 5 ===\n",
      "Padded batch shape: torch.Size([128, 23])\n",
      "\n",
      "=== Batch 6 ===\n",
      "Padded batch shape: torch.Size([128, 25])\n",
      "\n",
      "=== Batch 7 ===\n",
      "Padded batch shape: torch.Size([128, 22])\n",
      "\n",
      "=== Batch 8 ===\n",
      "Padded batch shape: torch.Size([128, 24])\n",
      "\n",
      "=== Batch 9 ===\n",
      "Padded batch shape: torch.Size([128, 26])\n",
      "\n",
      "=== Batch 10 ===\n",
      "Padded batch shape: torch.Size([128, 26])\n",
      "\n",
      "=== Batch 11 ===\n",
      "Padded batch shape: torch.Size([128, 31])\n",
      "\n",
      "=== Batch 12 ===\n",
      "Padded batch shape: torch.Size([128, 33])\n",
      "\n",
      "=== Batch 13 ===\n",
      "Padded batch shape: torch.Size([128, 27])\n",
      "\n",
      "=== Batch 14 ===\n",
      "Padded batch shape: torch.Size([128, 26])\n",
      "\n",
      "=== Batch 15 ===\n",
      "Padded batch shape: torch.Size([128, 27])\n",
      "\n",
      "=== Batch 16 ===\n",
      "Padded batch shape: torch.Size([128, 36])\n",
      "\n",
      "=== Batch 17 ===\n",
      "Padded batch shape: torch.Size([128, 29])\n",
      "\n",
      "=== Batch 18 ===\n",
      "Padded batch shape: torch.Size([128, 26])\n",
      "\n",
      "=== Batch 19 ===\n",
      "Padded batch shape: torch.Size([128, 24])\n",
      "\n",
      "=== Batch 20 ===\n",
      "Padded batch shape: torch.Size([128, 24])\n",
      "\n",
      "=== Batch 21 ===\n",
      "Padded batch shape: torch.Size([128, 23])\n",
      "\n",
      "=== Batch 22 ===\n",
      "Padded batch shape: torch.Size([128, 32])\n",
      "\n",
      "=== Batch 23 ===\n",
      "Padded batch shape: torch.Size([128, 25])\n",
      "\n",
      "=== Batch 24 ===\n",
      "Padded batch shape: torch.Size([128, 28])\n",
      "\n",
      "=== Batch 25 ===\n",
      "Padded batch shape: torch.Size([128, 28])\n",
      "\n",
      "=== Batch 26 ===\n",
      "Padded batch shape: torch.Size([128, 30])\n",
      "\n",
      "=== Batch 27 ===\n",
      "Padded batch shape: torch.Size([128, 25])\n",
      "\n",
      "=== Batch 28 ===\n",
      "Padded batch shape: torch.Size([128, 22])\n",
      "\n",
      "=== Batch 29 ===\n",
      "Padded batch shape: torch.Size([128, 29])\n",
      "\n",
      "=== Batch 30 ===\n",
      "Padded batch shape: torch.Size([128, 27])\n",
      "\n",
      "=== Batch 31 ===\n",
      "Padded batch shape: torch.Size([128, 28])\n",
      "\n",
      "=== Batch 32 ===\n",
      "Padded batch shape: torch.Size([128, 27])\n",
      "\n",
      "=== Batch 33 ===\n",
      "Padded batch shape: torch.Size([128, 22])\n",
      "\n",
      "=== Batch 34 ===\n",
      "Padded batch shape: torch.Size([128, 24])\n",
      "\n",
      "=== Batch 35 ===\n",
      "Padded batch shape: torch.Size([128, 30])\n",
      "\n",
      "=== Batch 36 ===\n",
      "Padded batch shape: torch.Size([128, 22])\n",
      "\n",
      "=== Batch 37 ===\n",
      "Padded batch shape: torch.Size([128, 27])\n",
      "\n",
      "=== Batch 38 ===\n",
      "Padded batch shape: torch.Size([128, 27])\n",
      "\n",
      "=== Batch 39 ===\n",
      "Padded batch shape: torch.Size([128, 25])\n",
      "\n",
      "=== Batch 40 ===\n",
      "Padded batch shape: torch.Size([128, 21])\n",
      "\n",
      "=== Batch 41 ===\n",
      "Padded batch shape: torch.Size([128, 27])\n",
      "\n",
      "=== Batch 42 ===\n",
      "Padded batch shape: torch.Size([128, 29])\n",
      "\n",
      "=== Batch 43 ===\n",
      "Padded batch shape: torch.Size([128, 28])\n",
      "\n",
      "=== Batch 44 ===\n",
      "Padded batch shape: torch.Size([128, 31])\n",
      "\n",
      "=== Batch 45 ===\n",
      "Padded batch shape: torch.Size([128, 21])\n",
      "\n",
      "=== Batch 46 ===\n",
      "Padded batch shape: torch.Size([128, 27])\n",
      "\n",
      "=== Batch 47 ===\n",
      "Padded batch shape: torch.Size([128, 23])\n",
      "\n",
      "=== Batch 48 ===\n",
      "Padded batch shape: torch.Size([128, 25])\n",
      "\n",
      "=== Batch 49 ===\n",
      "Padded batch shape: torch.Size([128, 26])\n",
      "\n",
      "=== Batch 50 ===\n",
      "Padded batch shape: torch.Size([128, 39])\n",
      "\n",
      "=== Batch 51 ===\n",
      "Padded batch shape: torch.Size([128, 25])\n",
      "\n",
      "=== Batch 52 ===\n",
      "Padded batch shape: torch.Size([128, 30])\n",
      "\n",
      "=== Batch 53 ===\n",
      "Padded batch shape: torch.Size([128, 22])\n",
      "\n",
      "=== Batch 54 ===\n",
      "Padded batch shape: torch.Size([128, 24])\n",
      "\n",
      "=== Batch 55 ===\n",
      "Padded batch shape: torch.Size([128, 26])\n",
      "\n",
      "=== Batch 56 ===\n",
      "Padded batch shape: torch.Size([128, 27])\n",
      "\n",
      "=== Batch 57 ===\n",
      "Padded batch shape: torch.Size([128, 33])\n",
      "\n",
      "=== Batch 58 ===\n",
      "Padded batch shape: torch.Size([128, 25])\n",
      "\n",
      "=== Batch 59 ===\n",
      "Padded batch shape: torch.Size([128, 25])\n",
      "\n",
      "=== Batch 60 ===\n",
      "Padded batch shape: torch.Size([128, 35])\n",
      "\n",
      "=== Batch 61 ===\n",
      "Padded batch shape: torch.Size([128, 21])\n",
      "\n",
      "=== Batch 62 ===\n",
      "Padded batch shape: torch.Size([128, 25])\n",
      "\n",
      "=== Batch 63 ===\n",
      "Padded batch shape: torch.Size([128, 26])\n",
      "\n",
      "=== Batch 64 ===\n",
      "Padded batch shape: torch.Size([128, 31])\n",
      "\n",
      "=== Batch 65 ===\n",
      "Padded batch shape: torch.Size([128, 24])\n",
      "\n",
      "=== Batch 66 ===\n",
      "Padded batch shape: torch.Size([128, 25])\n",
      "\n",
      "=== Batch 67 ===\n",
      "Padded batch shape: torch.Size([128, 24])\n",
      "\n",
      "=== Batch 68 ===\n",
      "Padded batch shape: torch.Size([128, 23])\n",
      "\n",
      "=== Batch 69 ===\n",
      "Padded batch shape: torch.Size([128, 26])\n",
      "\n",
      "=== Batch 70 ===\n",
      "Padded batch shape: torch.Size([128, 29])\n",
      "\n",
      "=== Batch 71 ===\n",
      "Padded batch shape: torch.Size([128, 27])\n",
      "\n",
      "=== Batch 72 ===\n",
      "Padded batch shape: torch.Size([128, 32])\n",
      "\n",
      "=== Batch 73 ===\n",
      "Padded batch shape: torch.Size([128, 29])\n",
      "\n",
      "=== Batch 74 ===\n",
      "Padded batch shape: torch.Size([128, 28])\n",
      "\n",
      "=== Batch 75 ===\n",
      "Padded batch shape: torch.Size([128, 30])\n",
      "\n",
      "=== Batch 76 ===\n",
      "Padded batch shape: torch.Size([128, 22])\n",
      "\n",
      "=== Batch 77 ===\n",
      "Padded batch shape: torch.Size([128, 25])\n",
      "\n",
      "=== Batch 78 ===\n",
      "Padded batch shape: torch.Size([128, 26])\n",
      "\n",
      "=== Batch 79 ===\n",
      "Padded batch shape: torch.Size([128, 23])\n",
      "\n",
      "=== Batch 80 ===\n",
      "Padded batch shape: torch.Size([128, 29])\n",
      "\n",
      "=== Batch 81 ===\n",
      "Padded batch shape: torch.Size([128, 25])\n",
      "\n",
      "=== Batch 82 ===\n",
      "Padded batch shape: torch.Size([128, 34])\n",
      "\n",
      "=== Batch 83 ===\n",
      "Padded batch shape: torch.Size([128, 23])\n",
      "\n",
      "=== Batch 84 ===\n",
      "Padded batch shape: torch.Size([128, 34])\n",
      "\n",
      "=== Batch 85 ===\n",
      "Padded batch shape: torch.Size([128, 22])\n",
      "\n",
      "=== Batch 86 ===\n",
      "Padded batch shape: torch.Size([128, 34])\n",
      "\n",
      "=== Batch 87 ===\n",
      "Padded batch shape: torch.Size([128, 33])\n",
      "\n",
      "=== Batch 88 ===\n",
      "Padded batch shape: torch.Size([128, 24])\n",
      "\n",
      "=== Batch 89 ===\n",
      "Padded batch shape: torch.Size([128, 23])\n",
      "\n",
      "=== Batch 90 ===\n",
      "Padded batch shape: torch.Size([128, 28])\n",
      "\n",
      "=== Batch 91 ===\n",
      "Padded batch shape: torch.Size([128, 29])\n",
      "\n",
      "=== Batch 92 ===\n",
      "Padded batch shape: torch.Size([128, 24])\n",
      "\n",
      "=== Batch 93 ===\n",
      "Padded batch shape: torch.Size([128, 24])\n",
      "\n",
      "=== Batch 94 ===\n",
      "Padded batch shape: torch.Size([128, 23])\n",
      "\n",
      "=== Batch 95 ===\n",
      "Padded batch shape: torch.Size([128, 26])\n",
      "\n",
      "=== Batch 96 ===\n",
      "Padded batch shape: torch.Size([128, 35])\n",
      "\n",
      "=== Batch 97 ===\n",
      "Padded batch shape: torch.Size([128, 28])\n",
      "\n",
      "=== Batch 98 ===\n",
      "Padded batch shape: torch.Size([128, 25])\n",
      "\n",
      "=== Batch 99 ===\n",
      "Padded batch shape: torch.Size([128, 25])\n",
      "\n",
      "=== Batch 100 ===\n",
      "Padded batch shape: torch.Size([128, 25])\n",
      "\n",
      "=== Batch 101 ===\n",
      "Padded batch shape: torch.Size([128, 21])\n",
      "\n",
      "=== Batch 102 ===\n",
      "Padded batch shape: torch.Size([128, 32])\n",
      "\n",
      "=== Batch 103 ===\n",
      "Padded batch shape: torch.Size([128, 26])\n",
      "\n",
      "=== Batch 104 ===\n",
      "Padded batch shape: torch.Size([128, 24])\n",
      "\n",
      "=== Batch 105 ===\n",
      "Padded batch shape: torch.Size([128, 28])\n",
      "\n",
      "=== Batch 106 ===\n",
      "Padded batch shape: torch.Size([128, 25])\n",
      "\n",
      "=== Batch 107 ===\n",
      "Padded batch shape: torch.Size([128, 24])\n",
      "\n",
      "=== Batch 108 ===\n",
      "Padded batch shape: torch.Size([128, 25])\n",
      "\n",
      "=== Batch 109 ===\n",
      "Padded batch shape: torch.Size([128, 25])\n",
      "\n",
      "=== Batch 110 ===\n",
      "Padded batch shape: torch.Size([128, 24])\n",
      "\n",
      "=== Batch 111 ===\n",
      "Padded batch shape: torch.Size([128, 39])\n",
      "\n",
      "=== Batch 112 ===\n",
      "Padded batch shape: torch.Size([128, 27])\n",
      "\n",
      "=== Batch 113 ===\n",
      "Padded batch shape: torch.Size([128, 21])\n",
      "\n",
      "=== Batch 114 ===\n",
      "Padded batch shape: torch.Size([128, 28])\n",
      "\n",
      "=== Batch 115 ===\n",
      "Padded batch shape: torch.Size([128, 30])\n",
      "\n",
      "=== Batch 116 ===\n",
      "Padded batch shape: torch.Size([128, 26])\n",
      "\n",
      "=== Batch 117 ===\n",
      "Padded batch shape: torch.Size([128, 27])\n",
      "\n",
      "=== Batch 118 ===\n",
      "Padded batch shape: torch.Size([128, 28])\n",
      "\n",
      "=== Batch 119 ===\n",
      "Padded batch shape: torch.Size([128, 26])\n",
      "\n",
      "=== Batch 120 ===\n",
      "Padded batch shape: torch.Size([128, 29])\n",
      "\n",
      "=== Batch 121 ===\n",
      "Padded batch shape: torch.Size([128, 26])\n",
      "\n",
      "=== Batch 122 ===\n",
      "Padded batch shape: torch.Size([128, 29])\n",
      "\n",
      "=== Batch 123 ===\n",
      "Padded batch shape: torch.Size([128, 24])\n",
      "\n",
      "=== Batch 124 ===\n",
      "Padded batch shape: torch.Size([128, 24])\n",
      "\n",
      "=== Batch 125 ===\n",
      "Padded batch shape: torch.Size([128, 31])\n",
      "\n",
      "=== Batch 126 ===\n",
      "Padded batch shape: torch.Size([128, 23])\n",
      "\n",
      "=== Batch 127 ===\n",
      "Padded batch shape: torch.Size([128, 28])\n",
      "\n",
      "=== Batch 128 ===\n",
      "Padded batch shape: torch.Size([128, 26])\n",
      "\n",
      "=== Batch 129 ===\n",
      "Padded batch shape: torch.Size([128, 36])\n",
      "\n",
      "=== Batch 130 ===\n",
      "Padded batch shape: torch.Size([128, 26])\n",
      "\n",
      "=== Batch 131 ===\n",
      "Padded batch shape: torch.Size([128, 26])\n",
      "\n",
      "=== Batch 132 ===\n",
      "Padded batch shape: torch.Size([128, 25])\n",
      "\n",
      "=== Batch 133 ===\n",
      "Padded batch shape: torch.Size([128, 24])\n",
      "\n",
      "=== Batch 134 ===\n",
      "Padded batch shape: torch.Size([128, 41])\n",
      "\n",
      "=== Batch 135 ===\n",
      "Padded batch shape: torch.Size([128, 38])\n",
      "\n",
      "=== Batch 136 ===\n",
      "Padded batch shape: torch.Size([128, 31])\n",
      "\n",
      "=== Batch 137 ===\n",
      "Padded batch shape: torch.Size([128, 29])\n",
      "\n",
      "=== Batch 138 ===\n",
      "Padded batch shape: torch.Size([128, 27])\n",
      "\n",
      "=== Batch 139 ===\n",
      "Padded batch shape: torch.Size([128, 30])\n",
      "\n",
      "=== Batch 140 ===\n",
      "Padded batch shape: torch.Size([128, 28])\n",
      "\n",
      "=== Batch 141 ===\n",
      "Padded batch shape: torch.Size([128, 27])\n",
      "\n",
      "=== Batch 142 ===\n",
      "Padded batch shape: torch.Size([128, 28])\n",
      "\n",
      "=== Batch 143 ===\n",
      "Padded batch shape: torch.Size([128, 27])\n",
      "\n",
      "=== Batch 144 ===\n",
      "Padded batch shape: torch.Size([128, 29])\n",
      "\n",
      "=== Batch 145 ===\n",
      "Padded batch shape: torch.Size([128, 26])\n",
      "\n",
      "=== Batch 146 ===\n",
      "Padded batch shape: torch.Size([128, 25])\n",
      "\n",
      "=== Batch 147 ===\n",
      "Padded batch shape: torch.Size([128, 29])\n",
      "\n",
      "=== Batch 148 ===\n",
      "Padded batch shape: torch.Size([128, 25])\n",
      "\n",
      "=== Batch 149 ===\n",
      "Padded batch shape: torch.Size([128, 30])\n",
      "\n",
      "=== Batch 150 ===\n",
      "Padded batch shape: torch.Size([128, 33])\n",
      "\n",
      "=== Batch 151 ===\n",
      "Padded batch shape: torch.Size([128, 27])\n",
      "\n",
      "=== Batch 152 ===\n",
      "Padded batch shape: torch.Size([128, 27])\n",
      "\n",
      "=== Batch 153 ===\n",
      "Padded batch shape: torch.Size([128, 34])\n",
      "\n",
      "=== Batch 154 ===\n",
      "Padded batch shape: torch.Size([128, 28])\n",
      "\n",
      "=== Batch 155 ===\n",
      "Padded batch shape: torch.Size([128, 29])\n",
      "\n",
      "=== Batch 156 ===\n",
      "Padded batch shape: torch.Size([128, 29])\n",
      "\n",
      "=== Batch 157 ===\n",
      "Padded batch shape: torch.Size([128, 28])\n",
      "\n",
      "=== Batch 158 ===\n",
      "Padded batch shape: torch.Size([128, 25])\n",
      "\n",
      "=== Batch 159 ===\n",
      "Padded batch shape: torch.Size([128, 27])\n",
      "\n",
      "=== Batch 160 ===\n",
      "Padded batch shape: torch.Size([128, 27])\n",
      "\n",
      "=== Batch 161 ===\n",
      "Padded batch shape: torch.Size([128, 27])\n",
      "\n",
      "=== Batch 162 ===\n",
      "Padded batch shape: torch.Size([128, 24])\n",
      "\n",
      "=== Batch 163 ===\n",
      "Padded batch shape: torch.Size([128, 30])\n",
      "\n",
      "=== Batch 164 ===\n",
      "Padded batch shape: torch.Size([128, 25])\n",
      "\n",
      "=== Batch 165 ===\n",
      "Padded batch shape: torch.Size([128, 30])\n",
      "\n",
      "=== Batch 166 ===\n",
      "Padded batch shape: torch.Size([128, 26])\n",
      "\n",
      "=== Batch 167 ===\n",
      "Padded batch shape: torch.Size([128, 35])\n",
      "\n",
      "=== Batch 168 ===\n",
      "Padded batch shape: torch.Size([128, 30])\n",
      "\n",
      "=== Batch 169 ===\n",
      "Padded batch shape: torch.Size([128, 26])\n",
      "\n",
      "=== Batch 170 ===\n",
      "Padded batch shape: torch.Size([128, 30])\n",
      "\n",
      "=== Batch 171 ===\n",
      "Padded batch shape: torch.Size([128, 24])\n",
      "\n",
      "=== Batch 172 ===\n",
      "Padded batch shape: torch.Size([128, 30])\n",
      "\n",
      "=== Batch 173 ===\n",
      "Padded batch shape: torch.Size([128, 30])\n",
      "\n",
      "=== Batch 174 ===\n",
      "Padded batch shape: torch.Size([128, 27])\n",
      "\n",
      "=== Batch 175 ===\n",
      "Padded batch shape: torch.Size([128, 29])\n",
      "\n",
      "=== Batch 176 ===\n",
      "Padded batch shape: torch.Size([128, 31])\n",
      "\n",
      "=== Batch 177 ===\n",
      "Padded batch shape: torch.Size([128, 27])\n",
      "\n",
      "=== Batch 178 ===\n",
      "Padded batch shape: torch.Size([128, 33])\n",
      "\n",
      "=== Batch 179 ===\n",
      "Padded batch shape: torch.Size([128, 26])\n",
      "\n",
      "=== Batch 180 ===\n",
      "Padded batch shape: torch.Size([128, 31])\n",
      "\n",
      "=== Batch 181 ===\n",
      "Padded batch shape: torch.Size([128, 27])\n",
      "\n",
      "=== Batch 182 ===\n",
      "Padded batch shape: torch.Size([128, 26])\n",
      "\n",
      "=== Batch 183 ===\n",
      "Padded batch shape: torch.Size([128, 27])\n",
      "\n",
      "=== Batch 184 ===\n",
      "Padded batch shape: torch.Size([128, 34])\n",
      "\n",
      "=== Batch 185 ===\n",
      "Padded batch shape: torch.Size([128, 32])\n",
      "\n",
      "=== Batch 186 ===\n",
      "Padded batch shape: torch.Size([128, 30])\n",
      "\n",
      "=== Batch 187 ===\n",
      "Padded batch shape: torch.Size([128, 30])\n",
      "\n",
      "=== Batch 188 ===\n",
      "Padded batch shape: torch.Size([128, 33])\n",
      "\n",
      "=== Batch 189 ===\n",
      "Padded batch shape: torch.Size([128, 25])\n",
      "\n",
      "=== Batch 190 ===\n",
      "Padded batch shape: torch.Size([128, 27])\n",
      "\n",
      "=== Batch 191 ===\n",
      "Padded batch shape: torch.Size([128, 32])\n",
      "\n",
      "=== Batch 192 ===\n",
      "Padded batch shape: torch.Size([128, 35])\n",
      "\n",
      "=== Batch 193 ===\n",
      "Padded batch shape: torch.Size([128, 28])\n",
      "\n",
      "=== Batch 194 ===\n",
      "Padded batch shape: torch.Size([128, 34])\n",
      "\n",
      "=== Batch 195 ===\n",
      "Padded batch shape: torch.Size([128, 31])\n",
      "\n",
      "=== Batch 196 ===\n",
      "Padded batch shape: torch.Size([128, 40])\n",
      "\n",
      "=== Batch 197 ===\n",
      "Padded batch shape: torch.Size([128, 31])\n",
      "\n",
      "=== Batch 198 ===\n",
      "Padded batch shape: torch.Size([128, 27])\n",
      "\n",
      "=== Batch 199 ===\n",
      "Padded batch shape: torch.Size([128, 29])\n",
      "\n",
      "=== Batch 200 ===\n",
      "Padded batch shape: torch.Size([128, 29])\n",
      "\n",
      "=== Batch 201 ===\n",
      "Padded batch shape: torch.Size([128, 31])\n",
      "\n",
      "=== Batch 202 ===\n",
      "Padded batch shape: torch.Size([128, 30])\n",
      "\n",
      "=== Batch 203 ===\n",
      "Padded batch shape: torch.Size([128, 33])\n",
      "\n",
      "=== Batch 204 ===\n",
      "Padded batch shape: torch.Size([128, 29])\n",
      "\n",
      "=== Batch 205 ===\n",
      "Padded batch shape: torch.Size([128, 35])\n",
      "\n",
      "=== Batch 206 ===\n",
      "Padded batch shape: torch.Size([128, 35])\n",
      "\n",
      "=== Batch 207 ===\n",
      "Padded batch shape: torch.Size([128, 24])\n",
      "\n",
      "=== Batch 208 ===\n",
      "Padded batch shape: torch.Size([128, 37])\n",
      "\n",
      "=== Batch 209 ===\n",
      "Padded batch shape: torch.Size([128, 30])\n",
      "\n",
      "=== Batch 210 ===\n",
      "Padded batch shape: torch.Size([128, 35])\n",
      "\n",
      "=== Batch 211 ===\n",
      "Padded batch shape: torch.Size([128, 28])\n",
      "\n",
      "=== Batch 212 ===\n",
      "Padded batch shape: torch.Size([128, 38])\n",
      "\n",
      "=== Batch 213 ===\n",
      "Padded batch shape: torch.Size([128, 23])\n",
      "\n",
      "=== Batch 214 ===\n",
      "Padded batch shape: torch.Size([128, 26])\n",
      "\n",
      "=== Batch 215 ===\n",
      "Padded batch shape: torch.Size([128, 35])\n",
      "\n",
      "=== Batch 216 ===\n",
      "Padded batch shape: torch.Size([128, 26])\n",
      "\n",
      "=== Batch 217 ===\n",
      "Padded batch shape: torch.Size([128, 38])\n",
      "\n",
      "=== Batch 218 ===\n",
      "Padded batch shape: torch.Size([128, 38])\n",
      "\n",
      "=== Batch 219 ===\n",
      "Padded batch shape: torch.Size([128, 26])\n",
      "\n",
      "=== Batch 220 ===\n",
      "Padded batch shape: torch.Size([128, 36])\n",
      "\n",
      "=== Batch 221 ===\n",
      "Padded batch shape: torch.Size([128, 28])\n",
      "\n",
      "=== Batch 222 ===\n",
      "Padded batch shape: torch.Size([128, 26])\n",
      "\n",
      "=== Batch 223 ===\n",
      "Padded batch shape: torch.Size([128, 30])\n",
      "\n",
      "=== Batch 224 ===\n",
      "Padded batch shape: torch.Size([128, 24])\n",
      "\n",
      "=== Batch 225 ===\n",
      "Padded batch shape: torch.Size([128, 25])\n",
      "\n",
      "=== Batch 226 ===\n",
      "Padded batch shape: torch.Size([72, 25])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from functools import partial\n",
    "\n",
    "loader = DataLoader(\n",
    "    enToken,\n",
    "    batch_size=128,\n",
    "    shuffle=False,  # QUAN TRỌNG\n",
    "    collate_fn=partial(collate_fn, vocab=en_vocab)\n",
    ")\n",
    "\n",
    "for batch_idx, (padded_batch, lengths) in enumerate(loader):\n",
    "    print(f\"\\n=== Batch {batch_idx} ===\")\n",
    "    print(\"Padded batch shape:\", padded_batch.shape)\n",
    "    # print(\"Lengths:\", lengths)\n",
    "\n",
    "for batch_idx, (padded_batch, lengths) in enumerate(loader):\n",
    "    # Đây là lengths gốc của 5 câu trong batch\n",
    "    lengths_sorted, sorted_idx = torch.sort(lengths, descending=True)\n",
    "    padded_sorted = padded_batch[sorted_idx]\n",
    "    \n",
    "    packed_input = pack_padded_sequence(padded_sorted, lengths_sorted, batch_first=True, enforce_sorted=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856caef7",
   "metadata": {},
   "source": [
    "# III. Build the model LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a1934c",
   "metadata": {},
   "source": [
    "## Encoder class building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ca8cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM():\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        pass\n",
    "    def sigmoid(x):\n",
    "        pass\n",
    "    def tanh(x):\n",
    "        pass\n",
    "    def inputGate(x):\n",
    "        pass\n",
    "    def stateGate():\n",
    "        pass\n",
    "    def forward(self, x, h, c):\n",
    "        pass\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
